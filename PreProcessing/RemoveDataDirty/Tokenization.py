from nltk import word_tokenize
def tokenization(string):
    string1=""
    words = word_tokenize(string)


    return words





